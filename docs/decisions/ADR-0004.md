# ADR: Verificaci√≥n de Citas Legales ‚Äî Determinista (C√≥digo) vs IA

**ID**: ADR-0004
**Fecha**: 2026-02-15
**Estado**: üü° Propuesto
**Autor**: Claude / Aritz

## 1. Contexto y Problema

OPTEK genera contenido educativo basado en legislaci√≥n (tests, correcciones, evaluaciones orales). El modelo LLM puede alucinar citas legales: inventar art√≠culos que no existen, atribuir contenido a art√≠culos incorrectos, o citar texto modificado. Para una app de oposiciones, una cita legal incorrecta es un defecto cr√≠tico que puede llevar a un suspenso. Necesitamos decidir c√≥mo verificar que cada cita legal en el output de Claude es correcta.

## 2. Opciones Consideradas

- **Opci√≥n A**: Verificaci√≥n determinista con c√≥digo ‚Äî Extraer citas con regex, buscarlas en la BD de legislaci√≥n curada, comparar contenido con matching algor√≠tmico. Sin IA en el paso de verificaci√≥n.
- **Opci√≥n B**: Verificaci√≥n con segundo LLM ‚Äî Usar Claude (u otro modelo) para revisar las citas y confirmar su validez. "IA verifica IA".
- **Opci√≥n C**: Verificaci√≥n h√≠brida ‚Äî C√≥digo para lookup de existencia + LLM para verificar coherencia sem√°ntica del contenido citado.
- **Opci√≥n D**: Sin verificaci√≥n (confiar en el modelo) ‚Äî Asumir que Claude con contexto RAG adecuado generar√° citas correctas.

## 3. Decisi√≥n Elegida: Verificaci√≥n Determinista (C√≥digo)

**Justificaci√≥n T√©cnica**:

1. **Fiabilidad 100%**: Un lookup en base de datos es binario: el art√≠culo existe o no, el contenido coincide o no. No hay margen de error probabil√≠stico.
2. **Coste cero**: No consume tokens adicionales de API. La verificaci√≥n es un SELECT a Supabase.
3. **Velocidad**: ~5-10ms por cita vs ~2-3 segundos si us√°ramos un segundo LLM. Para un test de 10 preguntas con ~30 citas, es ~300ms vs ~90s.
4. **Auditabilidad**: Cada paso de verificaci√≥n genera un log determinista que se puede reproducir exactamente.
5. **Principio arquitect√≥nico**: "Claude nunca habla sin art√≠culo exacto delante". Este principio es el diferenciador clave de OPTEK frente a competidores y requiere verificaci√≥n sin ambig√ºedad.
6. **Independencia del modelo**: Si cambiamos de Claude a otro modelo, la verificaci√≥n sigue funcionando id√©nticamente. No depende de las capacidades del LLM.

**Pipeline de verificaci√≥n** (detallado en `directives/OPTEK_verification.md`):

1. Extraer citas con regex: `Art\.\s*(\d+)(?:\.(\d+))?\s+(CE|LPAC|LRJSP|...)`
2. Lookup en BD: `SELECT * FROM legislacion WHERE ley_codigo = X AND articulo_numero = Y`
3. Content matching: comparar datos clave (plazos, √≥rganos, conceptos) entre cita y fuente
4. Score: verificada / parcial / no verificada
5. Si score < threshold ‚Üí descartar contenido o regenerar

## 4. Consecuencias (Trade-offs)

- **Positivas**: Cero alucinaciones en citas verificadas, coste cero de verificaci√≥n, latencia m√≠nima, reproducibilidad total, independencia del modelo LLM.
- **Negativas/Riesgos**: Requiere BD de legislaci√≥n curada y completa (el pipeline de ingesta es un prerequisito). Regex puede fallar en formatos de cita inesperados (mitigado: multiple regex patterns + fallback cascade). No verifica coherencia sem√°ntica profunda (mitigado: la comparaci√≥n de datos clave cubre los errores m√°s comunes).

## 5. Notas de Implementaci√≥n

- M√≥dulo principal: `/lib/ai/verification.ts`.
- 3 niveles de verificaci√≥n (cascade): exacto ‚Üí fuzzy con Levenshtein ‚Üí b√∫squeda por metadata.
- 5 tipos de content matching: plazo, √≥rgano/entidad, concepto jur√≠dico, procedimiento, cuant√≠a.
- Badges en UI: ‚úÖ Verificada (‚â•80%), ‚ö†Ô∏è Parcial (50-79%), ‚ùå No verificada (<50%).
- Tests en `tests/unit/verification.test.ts` con casos edge (art√≠culos bis, disposiciones adicionales, etc.).
- SOP completo: `directives/OPTEK_verification.md`.
